# LLMs-for-Toxic-Content-Detection

This repository contains the code for data generation and inference. The data generation code is located in the `datagen` folder, and the inference code is located in the `eval` folder.

Our fine-tuned 4B model can be found  \href{https://huggingface.co/zjj815/Qwen1.5-4B-Chinese-toxic-content-detection}{here}.


